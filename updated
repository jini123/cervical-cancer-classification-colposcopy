# =============================================
# Cervical Lesion Grading using SE-Residual CNN
# =============================================
# Author: Priyadarshini
# GitHub: https://github.com/jini123/cervical-cancer-classification-colposcopy/edit/main/updated
# Description: Deep learning pipeline for CIN1–CIN3 classification with SE blocks, PCA, class-wise augmentation,
# interpretability, and cross-domain validation
# =============================================

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.decomposition import PCA
from sklearn.metrics import classification_report, cohen_kappa_score

# -----------------------------
# TPU/GPU Strategy Setup
# -----------------------------
try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental_initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
    print("✅ Running on TPU")
except:
    strategy = tf.distribute.get_strategy()
    print("✅ Running on CPU/GPU")

# -----------------------------
# Squeeze-and-Excitation Block
# -----------------------------
def se_block(input_tensor, channels, reduction=16):
    se = layers.GlobalAveragePooling2D()(input_tensor)
    se = layers.Dense(channels // reduction, activation='relu')(se)
    se = layers.Dense(channels, activation='sigmoid')(se)
    se = layers.Reshape((1, 1, channels))(se)
    return layers.Multiply()([input_tensor, se])

# -----------------------------
# Residual Convolutional Block
# -----------------------------
def conv_block(x, filters):
    shortcut = x
    x = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)
    shortcut = layers.Conv2D(filters, (1, 1), padding='same')(shortcut)
    x = layers.Add()([x, shortcut])
    x = layers.MaxPooling2D((2, 2))(x)
    return se_block(x, filters)

# -----------------------------
# Build SE-Residual CNN Model
# -----------------------------
def build_model(input_shape=(224, 224, 3), num_classes=3):
    inputs = layers.Input(shape=input_shape)
    x = conv_block(inputs, 64)
    x = conv_block(x, 128)
    x = conv_block(x, 256)
    x = conv_block(x, 512)
    x = conv_block(x, 512)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(1024, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)
    return models.Model(inputs, outputs)

# -----------------------------
# Class-wise Data Augmentation
# -----------------------------
def classwise_generator(base_dir, target_size=(224, 224), batch_size=32):
    classes = ['CIN1', 'CIN2', 'CIN3']
    augment_config = {
        'CIN1': dict(rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.3, zoom_range=0.3),
        'CIN2': dict(rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.3, zoom_range=0.3),
        'CIN3': dict(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1)
    }
    generators = []
    for cls in classes:
        datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, fill_mode='nearest', **augment_config[cls])
        gen = datagen.flow_from_directory(
            base_dir,
            target_size=target_size,
            batch_size=batch_size,
            classes=[cls],
            class_mode='categorical',
            shuffle=True
        )
        generators.append(gen)
    return generators

def mix_generators(generators):
    while True:
        for gen in generators:
            yield next(gen)

# -----------------------------
# PCA Feature Reduction (Optional)
# -----------------------------
def apply_pca(model, dataset):
    intermediate_model = models.Model(inputs=model.input, outputs=model.layers[-3].output)
    features = intermediate_model.predict(dataset)
    pca = PCA(n_components=0.95)
    reduced = pca.fit_transform(features)
    return reduced, pca

# -----------------------------
# Cross-domain Evaluation
# -----------------------------
def evaluate_cross_domain(model, dataset):
    result = model.evaluate(dataset)
    print("✅ Cross-domain Accuracy:", result[1])

# -----------------------------
# Grad-CAM / Grad-CAM++ Placeholder
# -----------------------------
# You can use tf-keras-vis or captum for implementation

# -----------------------------
# Training & TFLite Export
# -----------------------------
with strategy.scope():
    model = build_model()
    model.compile(optimizer=optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

    train_gens = classwise_generator("data/primary_dataset")
    val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory("data/validation_dataset", target_size=(224, 224), batch_size=32, class_mode='categorical')
    test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory("data/secondary_dataset", target_size=(224, 224), batch_size=32, class_mode='categorical')

    history = model.fit(
        mix_generators(train_gens),
        validation_data=val_gen,
        steps_per_epoch=180,
        epochs=100,
        callbacks=[callbacks.EarlyStopping(patience=10, restore_best_weights=True)]
    )

    evaluate_cross_domain(model, test_gen)

    model.save("cin_grading_model.h5")
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    tflite_model = converter.convert()
    with open("cin_model_quant.tflite", "wb") as f:
        f.write(tflite_model)

    print("✅ Training complete | Model saved & quantized.")



